{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "081aa63a-c326-4e4e-9639-08620d834be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pierwsze 15 prognozowanych klas:\n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0]\n",
      "Pierwsze 15 wartości ze zbioru walidacyjnego:\n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0]\n",
      "Dokładność modelu: 100.00%\n",
      "Dokładność dla zbioru treningowego: 96.67%\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Załaduj zbiór danych Iris\n",
    "dataset_iris = load_iris()\n",
    "\n",
    "# Podziel zbiór danych na część treningową i walidacyjną\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(dataset_iris.data, dataset_iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicjalizuj model KNeighborsRegressor z parametrem liczby sąsiadów równym 2\n",
    "model = KNeighborsRegressor(n_neighbors=2)\n",
    "\n",
    "# Trenuj model na części treningowej zbioru\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# A. Wyznacz prognozowane klasy (y_prediction) za pomocą wytrenowanego modelu używając części walidacyjnej zbioru.\n",
    "y_prediction = model.predict(X_valid)\n",
    "\n",
    "# B. Wyświetl 15 pierwszych prognozowanych klas i porównaj z pierwszymi 15 wartościami ze zbioru walidacyjnego (y_valid)\n",
    "print(\"Pierwsze 15 prognozowanych klas:\")\n",
    "print(y_prediction[:15])\n",
    "print(\"Pierwsze 15 wartości ze zbioru walidacyjnego:\")\n",
    "print(y_valid[:15])\n",
    "\n",
    "# C. Używając walidacyjnej części zbioru wyznacz dokładność (accuracy) dla przygotowanego modelu.\n",
    "accuracy = accuracy_score(y_valid, y_prediction.round())\n",
    "# D. Zinterpretuj uzyskaną dokładność\n",
    "# Wartości docelowe dla zbioru Iris są liczbami całkowitymi odpowiadającymi klasom: 0, 1 lub 2.\n",
    "# Dokładność to stosunek poprawnych prognoz do wszystkich prognoz.\n",
    "\n",
    "print(\"Dokładność modelu: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# E. Porównaj dokładność wyznaczoną dla zbioru walidacyjnego i dla zbioru treningowego\n",
    "# Dokładność dla zbioru treningowego może być wyższa niż dla zbioru walidacyjnego, jeśli model został przeuczony na danych treningowych.\n",
    "# Niższa dokładność dla zbioru walidacyjnego może wskazywać na zjawisko przeuczenia.\n",
    "# Dlatego ważne jest monitorowanie zarówno dokładności zbioru treningowego, jak i walidacyjnego.\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred.round())\n",
    "print(\"Dokładność dla zbioru treningowego: {:.2f}%\".format(train_accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4be0322-b4c9-40f7-91b6-690849f28730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 2. 1. 1. 0. 1. 2. 1. 1.]\n",
      "[1 0 2 1 1 0 1 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "#1 V.\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "# Załaduj zbiór danych Iris\n",
    "dataset_iris = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset_iris.data, dataset_iris.target, test_size=0.2, random_state=42)\n",
    "model = KNeighborsRegressor(n_neighbors=2)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_prediction = model.predict(X_test)\n",
    "print(y_prediction[:10])\n",
    "print(y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "097667ad-fc6f-4174-9a68-242983924771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precyzja klasyfikacji: 1.00\n",
      "Czułość klasyfikacji: 1.00\n",
      "F1-score: 1.00\n",
      "Współczynnik Mathewsa: 1.00\n",
      "Macierz pomyłek:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "Raport klasyfikacji:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix, classification_report\n",
    "\n",
    "# A. Precyzja klasyfikacji\n",
    "precision = precision_score(y_test, y_prediction.round(), average='weighted')\n",
    "print(\"Precyzja klasyfikacji: {:.2f}\".format(precision))\n",
    "\n",
    "# B. Czułość klasyfikacji\n",
    "recall = recall_score(y_test, y_prediction.round(), average='weighted')\n",
    "print(\"Czułość klasyfikacji: {:.2f}\".format(recall))\n",
    "\n",
    "# C. F1-score i współczynnik Mathewsa\n",
    "f1 = f1_score(y_test, y_prediction.round(), average='weighted')\n",
    "matthews = matthews_corrcoef(y_test, y_prediction.round())\n",
    "print(\"F1-score: {:.2f}\".format(f1))\n",
    "print(\"Współczynnik Mathewsa: {:.2f}\".format(matthews))\n",
    "\n",
    "# D. Macierz pomyłek\n",
    "conf_matrix = confusion_matrix(y_test, y_prediction.round())\n",
    "print(\"Macierz pomyłek:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# E. Raport klasyfikacji\n",
    "classification_rep = classification_report(y_test, y_prediction.round())\n",
    "print(\"Raport klasyfikacji:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8b8da91-7455-49d1-b463-11454dfa5cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pierwsze 10 prognoz:\n",
      "[134.  128.5 116.   92.5 101.5 146.5 202.   94.5  78.  206. ]\n",
      "Pierwsze 10 wartości ze zbioru walidacyjnego:\n",
      "[225. 102. 182.  83. 220. 113. 151.  96.  72. 191.]\n",
      "Średni błąd bezwzględny (MAE): 51.13\n",
      "Średni błąd bezwzględny dla zbioru treningowego: 32.29\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Załaduj zbiór danych diabetes\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "# Podziel zbiór danych na część treningową i walidacyjną\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(diabetes.data, diabetes.target, train_size=250)\n",
    "\n",
    "# Inicjalizuj model KNeighborsRegressor z parametrem liczby sąsiadów równym 2\n",
    "model = KNeighborsRegressor(n_neighbors=2)\n",
    "\n",
    "# Trenuj model na części treningowej zbioru\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# A. Wyznacz prognozy (y_prediction) za pomocą wytrenowanego modelu używając części walidacyjnej zbioru\n",
    "y_prediction = model.predict(X_valid)\n",
    "\n",
    "# B. Wyświetl 10 pierwszych prognoz i porównaj z pierwszymi 10 wartościami ze zbioru walidacyjnego (y_valid)\n",
    "print(\"Pierwsze 10 prognoz:\")\n",
    "print(y_prediction[:10])\n",
    "print(\"Pierwsze 10 wartości ze zbioru walidacyjnego:\")\n",
    "print(y_valid[:10])\n",
    "\n",
    "# C. Używając walidacyjnej części zbioru wyznacz średni błąd bezwzględny - MAE (mean absolute error) dla przygotowanego modelu\n",
    "mae = mean_absolute_error(y_valid, y_prediction)\n",
    "print(\"Średni błąd bezwzględny (MAE): {:.2f}\".format(mae))\n",
    "\n",
    "# D. Zinterpretuj wyznaczony błąd\n",
    "# Wartości docelowe dla zbioru diabetes są kontynuacyjne, reprezentując progresję choroby.\n",
    "# Średni błąd bezwzględny mierzy średnią wartość bezwzględną różnicy między rzeczywistymi a prognozowanymi wartościami.\n",
    "# Im niższy MAE, tym lepiej model przewiduje wartości docelowe.\n",
    "\n",
    "# E. Porównaj średni błąd bezwzględny wyznaczony dla zbioru walidacyjnego i dla zbioru treningowego\n",
    "# Różnica między MAE dla zbioru treningowego a walidacyjnego może wskazywać na to, czy model jest przeuczony lub niedotrenowany.\n",
    "# Należy monitorować oba MAE, aby zrozumieć ogólną wydajność modelu.\n",
    "y_train_pred = model.predict(X_train)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "print(\"Średni błąd bezwzględny dla zbioru treningowego: {:.2f}\".format(train_mae))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bec423e1-daa1-4bdf-8dc4-a2f97e32f249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Błąd średniokwadratowy (MSE): 9578.51\n",
      "Podstawowy błąd średniokwadratowy (RMSE):  97.86987800561178\n",
      "Średni bezwzględny błąd procentowy (MAPE):  0.7292934150332533\n",
      "Współczynnik determinacji (R^2):  -0.70343455754676\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Załaduj zbiór danych diabetes\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "# Podziel zbiór danych na część treningową i walidacyjną\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(diabetes.data, diabetes.target, train_size=250)\n",
    "\n",
    "\n",
    "# A. Błąd średniokwadratowy - MSE\n",
    "mse = mean_squared_error(y_valid, y_prediction)\n",
    "print(\"Błąd średniokwadratowy (MSE): {:.2f}\".format(mse))\n",
    "\n",
    "# B. Podstawowy błąd średniokwadratowy - RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Podstawowy błąd średniokwadratowy (RMSE): \", rmse)\n",
    "\n",
    "# C. Średni bezwzględny błąd procentowy - MAPE\n",
    "# Pamiętaj, żeby uniknąć dzielenia przez zero, wartości prognozowane muszą być różne od zera.\n",
    "# W przeciwnym razie mogą być obciążone, co wpłynie na MAPE.\n",
    "mape = mean_absolute_percentage_error(y_valid, y_prediction)\n",
    "print(\"Średni bezwzględny błąd procentowy (MAPE): \", mape)\n",
    "\n",
    "# D. Współczynnik determinacji - R^2\n",
    "r_squared = r2_score(y_valid, y_prediction)\n",
    "print(\"Współczynnik determinacji (R^2): \", r_squared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b293a2d-3ebb-4e49-8967-36f8ea3ef6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec886787-53ad-41b3-8bb6-c6d0dc95e94d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e72cefab-f304-4ef7-a4f5-5b3fd5f359b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pierwsze 15 prognozowanych klas: \n",
      "[1. 0. 2. 1. 1. 0. 1. 2. 1. 1. 2. 0. 0. 0. 0.]\n",
      "Pierwsze 15 wartosci ze zbioru walidacyjnego: \n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0]\n",
      "Celnosc naszego modelu dla zbioru walidacyjnego: 100.00%\n",
      "Celnosc naszego modelu dla zbioru treningowego: 97.50%\n"
     ]
    }
   ],
   "source": [
    "#1v\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "#from sklearn.metrics import\n",
    "\n",
    "dataset_iris = load_iris()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(dataset_iris.data, dataset_iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=2)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_prediction = model.predict(X_valid)\n",
    "\n",
    "print(\"Pierwsze 15 prognozowanych klas: \")\n",
    "print(y_prediction[:15])\n",
    "print(\"Pierwsze 15 wartosci ze zbioru walidacyjnego: \")\n",
    "print(y_valid[:15])\n",
    "\n",
    "accuracy = accuracy_score(y_valid, y_prediction.round())\n",
    "print(\"Celnosc naszego modelu dla zbioru walidacyjnego: {:.2f}%\".format(accuracy*100))\n",
    "\n",
    "train_y_prediction = model.predict(X_train)\n",
    "t_accuracy = accuracy_score(y_train, train_y_prediction.round())\n",
    "print(\"Celnosc naszego modelu dla zbioru treningowego: {:.2f}%\".format(t_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "91872754-c531-4002-9351-8851341aafcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precyzja:  100.0 %\n",
      "Czulosc:  100.0 %\n",
      "F1:  100.0 %\n",
      "Matthews:  100.0 %\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "Raport\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2v\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix, classification_report\n",
    "\n",
    "precision = precision_score(y_valid, y_prediction.round(), average='weighted')\n",
    "print(\"Precyzja: \", precision*100,\"%\")\n",
    "\n",
    "recall = recall_score(y_valid, y_prediction.round(), average='weighted')\n",
    "print(\"Czulosc: \", recall*100,\"%\")\n",
    "\n",
    "f1 = f1_score(y_valid, y_prediction.round(), average='weighted')\n",
    "print(\"F1: \", f1*100,\"%\")\n",
    "\n",
    "mat = matthews_corrcoef(y_valid, y_prediction.round())\n",
    "print(\"Matthews: \", mat*100,\"%\")\n",
    "\n",
    "macpom = confusion_matrix(y_valid, y_prediction.round())\n",
    "print(macpom)\n",
    "\n",
    "report = classification_report(y_valid, y_prediction.round())\n",
    "print(\"Raport\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d6799d0c-c46f-43c9-9ae8-0869e2a2ad7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[226.  175.5  63.5 161.5 194.  181.  213.5 243.   55.  128.5]\n",
      "[150.  55. 116.  73.  84.  81.  89. 189.  77.  68.]\n",
      "MAE:  47.299479166666664\n",
      "[151.  75. 141. 206. 135.]\n",
      "MAE:\n",
      "47.299479166666664\n",
      "36.566\n"
     ]
    }
   ],
   "source": [
    "#3v\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, train_size=250)\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=2)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#A \n",
    "y_prediction = model.predict(X_test)\n",
    "#B\n",
    "print(y_prediction[:10])\n",
    "print(y_test[:10])\n",
    "#C, D - wytlumacz\n",
    "mae = mean_absolute_error(y_test, y_prediction)\n",
    "\n",
    "print(\"MAE: \", mae)\n",
    "print(diabetes.target[:5])\n",
    "\n",
    "#E\n",
    "y_train_pred = model.predict(X_train)\n",
    "mae_t = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "print(\"MAE:\")\n",
    "print(mae)\n",
    "print(mae_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3ecd2e06-6a9c-43a3-988d-04e153133060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4v\n",
    "#DLA ZBIORU VALIDACYJNEGO - TEST\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "mse = mean_squared_error(y_test, y_prediction)\n",
    "rmse = np.sqrt(mse)\n",
    "mape = mean_absolute_percentage_error(y_test, y_prediction)\n",
    "r2 = r2_score(y_test, y_prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22dee1ca-3519-4bb5-b49f-7eb157625bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 0 0 1 0 0 0 0 0 1]\n",
      "[0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      "86.0 %\n",
      "Dokladnosc dla danych walidacyjnych:\n",
      "86.0 %\n",
      "Dokladnosc dla danych testowych:\n",
      "95.75 %\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X_bin, y_bin = make_classification(n_samples=500, n_features=5, n_classes=2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bin, y_bin, test_size=0.2, random_state=42)\n",
    "\n",
    "object = KNeighborsRegressor(n_neighbors=2)\n",
    "object.fit(X_train, y_train)\n",
    "\n",
    "y_prediction = object.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_prediction.round())\n",
    "\n",
    "print(y_test[:15])\n",
    "print(y_prediction[:15])\n",
    "\n",
    "print(acc*100, \"%\")\n",
    "\n",
    "y_train_prediction = object.predict(X_train)\n",
    "train_acc = accuracy_score(y_train, y_train_prediction.round())\n",
    "\n",
    "print(\"Dokladnosc dla danych walidacyjnych:\")\n",
    "print(acc*100, \"%\")\n",
    "print(\"Dokladnosc dla danych testowych:\")\n",
    "print(train_acc*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94141a81-9c4d-433e-8e64-0f98e8eefdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.5546875\n",
      "30.326\n"
     ]
    }
   ],
   "source": [
    "#3vv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, train_size=250)\n",
    "model = KNeighborsRegressor(n_neighbors=2)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "y_t_pred = model.predict(X_train)\n",
    "tmae = mean_absolute_error(y_train, y_t_pred)\n",
    "\n",
    "print(mae)\n",
    "print(tmae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "addb84ab-b73c-4dbe-bdbb-47aac7108677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4vv\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18838f86-5769-4222-8e7d-fc740a06ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.\n",
    "from sklearn.\n",
    "\n",
    "X_reg2, y_reg2 = make_regression(n_samples=600, n_features=6) #zbior z z6l3\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reg2, y_reg2, test_size=0.2, random_state=42)\n",
    "model = KN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
